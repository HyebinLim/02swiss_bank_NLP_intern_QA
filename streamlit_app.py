import streamlit as st
from helper import get_openai_api_key
from utils import get_doc_tools
from llama_index.llms.openai import OpenAI
from llama_index.core.agent import FunctionCallingAgentWorker
from llama_index.core.agent import AgentRunner
import os
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Swiss Bank AI/NLP Job Q&A",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- ì•± ì„¤ëª… í‘œì‹œ ---
# CSSë¡œ ë„¤ëª¨ìƒì ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap');
* {
    font-family: 'Poppins', sans-serif;
}
.custom-box {
    background-color: #e6f3ff;
    padding: 5px 20px;
    border-radius: 10px;
    margin: 10px 0;
    font-family: 'Poppins', sans-serif;
    display: flex;
    align-items: center;
    min-height: 50px;
}
.custom-box h3 {
    font-family: 'Poppins', sans-serif;
    font-weight: 600;
    margin: 0;
    color: #2c3e50;
}
.custom-desc-list {
    font-family: 'Poppins', sans-serif;
}
.custom-desc-list li {
    margin-bottom: 2px;
    margin-top: 2px;
    font-family: 'Poppins', sans-serif;
    font-weight: 400;
    color: #34495e;
    font-size: 14px;
}
h2 {
    font-family: 'Poppins', sans-serif;
    font-size: 16px;
    font-weight: 500;
}
</style>
""", unsafe_allow_html=True)

st.markdown('<div class="custom-box"><h3>Want a Swiss Bank AI/NLP job?</h3></div>', unsafe_allow_html=True)
st.markdown('''
<div class="custom-desc-list">
<ul>
<li>Ask me anything about my journey to become an AI/NLP scientist at a bank in Switzerland during my master's at University of Zurich.</li>
<li>Answers based on <a href="https://blog.naver.com/imyourbest" target="_blank">89% ì§ì¥ì¸ ì¼ì§€</a></li>
</ul>
</div>
''', unsafe_allow_html=True)

# --- API í‚¤ ì…ë ¥ ---
if 'OPENAI_API_KEY' not in st.session_state:
    st.session_state['OPENAI_API_KEY'] = ''

# API í‚¤ ì¬ì„¤ì • ë²„íŠ¼ì€ Q&A ì‹œìŠ¤í…œ ë¡œë“œ í›„ì— í‘œì‹œë©ë‹ˆë‹¤

api_key = st.text_input(
    "ğŸ”‘ Enter your OpenAI API key:",
    type="password",
    value=st.session_state['OPENAI_API_KEY'],
    key="api_key_input"
)

# API í‚¤ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
if api_key and api_key != st.session_state['OPENAI_API_KEY']:
    st.session_state['OPENAI_API_KEY'] = api_key
    st.session_state['agent_loaded'] = False
    st.success("âœ… API key updated! Please wait for the system to load...")

def translate_to_english(question, api_key):
    """í•œêµ­ì–´ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­"""
    try:
        import os
        # proxies ì„¤ì • ì œê±° (OpenAI 1.56.0+ í˜¸í™˜ì„±)
        proxy_vars = ["OPENAI_PROXY", "HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY"]
        for var in proxy_vars:
            if var in os.environ:
                del os.environ[var]
            
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful translator specializing in job-related questions. Translate the user's question to English, focusing on job search, career, salary, requirements, and workplace topics. If the question is already in English, return it as is. Only return the translated question, nothing else. Be precise with job-related terminology."},
                {"role": "user", "content": question}
            ],
            temperature=0
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"Translation failed: {str(e)}. Using original question.")
        return question

def extract_source_pages(response):
    """ì‘ë‹µì—ì„œ ì†ŒìŠ¤ í˜ì´ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” ê°œì„ ëœ í•¨ìˆ˜ - ìƒìœ„ 3-5ê°œë§Œ í‘œì‹œ"""
    try:
        sources = getattr(response, 'sources', None)
        if not sources:
            return None
            
        pages = set()
        for src in sources:
            raw_output = getattr(src, "raw_output", None)
            if raw_output is None:
                continue
                
            # source_nodesê°€ ìˆëŠ” ê²½ìš°
            meta_dict = getattr(raw_output, "source_nodes", [])
            if meta_dict:
                for node_with_score in meta_dict:
                    node = node_with_score.node
                    if hasattr(node, "metadata"):
                        md = node.metadata
                        if "page_label" in md:
                            pages.add(md["page_label"])
            
            # ì§ì ‘ metadataê°€ ìˆëŠ” ê²½ìš°
            if hasattr(raw_output, "metadata"):
                md = raw_output.metadata
                if "page_label" in md:
                    pages.add(md["page_label"])
        
        if pages:
            # í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ì—¬ ì •ë ¬
            sorted_pages = sorted([int(p) if p.isdigit() else 0 for p in pages])
            # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
            top_pages = sorted_pages[:5]
            return [str(p) for p in top_pages]
        return None
    except Exception as e:
        st.warning(f"Error extracting source pages: {str(e)}")
        return None

# --- Q&A ê¸°ëŠ¥ ì¤€ë¹„ ---
if st.session_state['OPENAI_API_KEY']:
    # ë¬¸ì„œ ë„êµ¬ ë° ì—ì´ì „íŠ¸ ì¤€ë¹„ (ìºì‹±)
    @st.cache_resource(show_spinner=True)
    def load_tools_and_agent(api_key):
        try:
            import os
            os.environ["OPENAI_API_KEY"] = api_key
            # proxies ì„¤ì • ì œê±° (OpenAI 1.56.0+ í˜¸í™˜ì„±)
            proxy_vars = ["OPENAI_PROXY", "HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY"]
            for var in proxy_vars:
                if var in os.environ:
                    del os.environ[var]
            
            # PDF íŒŒì¼ ì¡´ì¬ í™•ì¸ (ì›ë³¸ ì‚¬ìš© - í…ìŠ¤íŠ¸ ë³´ì¡´)
            pdf_path = "swiss_bank_job.pdf"
            if not os.path.exists(pdf_path):
                st.error(f"PDF file not found: {pdf_path}")
                return None
                
            vector_tool, summary_tool = get_doc_tools(pdf_path, "swissbankjob")
            llm = OpenAI(model="gpt-3.5-turbo", temperature=0)
            agent_worker = FunctionCallingAgentWorker.from_tools(
                [vector_tool, summary_tool],
                llm=llm,
                verbose=False
            )
            agent = AgentRunner(agent_worker)
            return agent
        except Exception as e:
            st.error(f"Error loading tools and agent: {str(e)}")
            return None

    # ì—ì´ì „íŠ¸ ë¡œë”© ìƒíƒœ í™•ì¸
    if 'agent_loaded' not in st.session_state:
        st.session_state['agent_loaded'] = False

    # API í‚¤ ì¬ì„¤ì • ì‹œ ìºì‹œ í´ë¦¬ì–´
    if st.button("ğŸ”„ Reset API Key"):
        st.session_state['OPENAI_API_KEY'] = ''
        st.session_state['agent_loaded'] = False
        load_tools_and_agent.clear()
        st.rerun()

    if not st.session_state['agent_loaded']:
        with st.spinner("Loading Q&A system..."):
            agent = load_tools_and_agent(st.session_state['OPENAI_API_KEY'])
            if agent is not None:
                st.session_state['agent'] = agent
                st.session_state['agent_loaded'] = True
                st.success("âœ… Q&A system loaded successfully!")
            else:
                st.error("âŒ Failed to load Q&A system. Please check your API key and try again.")
    else:
        agent = st.session_state['agent']

    if st.session_state['agent_loaded'] and agent is not None:
        st.markdown("---")
        st.subheader("Ask questions about the Swiss bank AI/NLP scientist job!")
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'question_submitted' not in st.session_state:
            st.session_state.question_submitted = False
        if 'current_question' not in st.session_state:
            st.session_state.current_question = ""
        
        question = st.text_input("Your question:", key="question_input", on_change=lambda: setattr(st.session_state, 'question_submitted', True))
        
        # ì—”í„°í‚¤ ì…ë ¥ ê°ì§€ ë° ì§ˆë¬¸ ì²˜ë¦¬
        if st.session_state.question_submitted and question and question != st.session_state.current_question:
            st.session_state.current_question = question
            st.session_state.question_submitted = False
            
            try:
                with st.spinner("Processing your question..."):
                    # í•œêµ­ì–´ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­
                    translated_question = translate_to_english(question, st.session_state['OPENAI_API_KEY'])
                    
                    # ë²ˆì—­ëœ ì§ˆë¬¸ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
                    response = agent.chat(translated_question)
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.markdown(f"**ğŸ—£ï¸ Question:** {question}")
                    st.markdown(f"**ğŸ’¬ Answer:** {response.response}")
                    
                    # ì‘ë‹µ ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ì‹¤ì œë¡œ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
                    answer_text = response.response.lower()
                    no_info_keywords = ['no information', 'not found', 'not available', 'not mentioned', 'not provided', 'not specified', 'not stated', 'not given', 'not included', 'not listed', 'not detailed', 'not described', 'not outlined', 'not covered', 'not addressed', 'not discussed', 'not revealed', 'not disclosed', 'not shared', 'not indicated']
                    
                    has_information = not any(keyword in answer_text for keyword in no_info_keywords)
                    
                    # ì†ŒìŠ¤ í˜ì´ì§€ ì¶”ì¶œ ë° í‘œì‹œ (ì •ë³´ê°€ ìˆì„ ë•Œë§Œ)
                    if has_information:
                        source_pages = extract_source_pages(response)
                        if source_pages:
                            st.info(f"ğŸ“Œ Source page(s): {', '.join(source_pages)}")
                            st.info("ğŸ“„ Data source: [GitHub PDF](https://github.com/HyebinLim/02swiss_bank_NLP_intern_QA/blob/master/swiss_bank_job.pdf)")
                        else:
                            st.info("ğŸ“Œ Answer generated from document content (specific pages not available)")
                            st.info("ğŸ“„ Data source: [GitHub PDF](https://github.com/HyebinLim/02swiss_bank_NLP_intern_QA/blob/master/swiss_bank_job.pdf)")
                    else:
                        st.warning("âš ï¸ No information found in the document for this question.")
                            
            except Exception as e:
                st.error(f"Error processing question: {str(e)}")
    elif not st.session_state['agent_loaded']:
        st.info("Please wait while the Q&A system is loading...")
# API í‚¤ ì…ë ¥ ì•ˆë‚´ ë©”ì‹œì§€ ì œê±° 